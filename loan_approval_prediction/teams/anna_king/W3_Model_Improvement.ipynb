{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:12:09.334062Z","iopub.status.busy":"2024-11-18T16:12:09.333416Z","iopub.status.idle":"2024-11-18T16:12:10.926048Z","shell.execute_reply":"2024-11-18T16:12:10.924856Z","shell.execute_reply.started":"2024-11-18T16:12:09.334020Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import seaborn as sns"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:12:10.927938Z","iopub.status.busy":"2024-11-18T16:12:10.927403Z","iopub.status.idle":"2024-11-18T16:12:11.042194Z","shell.execute_reply":"2024-11-18T16:12:11.040985Z","shell.execute_reply.started":"2024-11-18T16:12:10.927865Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","data_folder = os.getcwd().split(\"loan_approval_prediction\")[0] + \"loan_approval_prediction\\\\data\\\\\"\n","df = pd.read_csv(data_folder + 'credit_risk_dataset.csv')  \n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Cleaning"]},{"cell_type":"markdown","metadata":{},"source":["## Remove Duplicates "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:12:13.258575Z","iopub.status.busy":"2024-11-18T16:12:13.258177Z","iopub.status.idle":"2024-11-18T16:12:13.310678Z","shell.execute_reply":"2024-11-18T16:12:13.309588Z","shell.execute_reply.started":"2024-11-18T16:12:13.258534Z"},"trusted":true},"outputs":[],"source":["# Identify duplicate rows\n","duplicates = df.duplicated(keep='first')\n","num_duplicates = duplicates.sum()\n","\n","# Remove duplicate rows\n","df = df.drop_duplicates(keep='first')\n","\n","print('no. duplicates: ', num_duplicates)"]},{"cell_type":"markdown","metadata":{},"source":["## Change data types as appropriate - not including categorical data, yet"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:12:13.312219Z","iopub.status.busy":"2024-11-18T16:12:13.311869Z","iopub.status.idle":"2024-11-18T16:12:13.325361Z","shell.execute_reply":"2024-11-18T16:12:13.324198Z","shell.execute_reply.started":"2024-11-18T16:12:13.312183Z"},"trusted":true},"outputs":[],"source":["df['person_emp_length'] = df['person_emp_length'].fillna(-1)\n","df['loan_int_rate'] = df['loan_int_rate'].fillna(-1)\n","\n","# We're also adding 'missing indicator' fields to explicity call out rows with missing data:\n","df['missing_emp_length'] = (df['person_emp_length'] == -1).astype(int)\n","df['missing_loan_rate'] = (df['loan_int_rate'] == -1).astype(int)\n","\n","df['person_age'] = df['person_age'].astype('uint8')\n","df['person_income'] = df['person_income'].astype('uint32')\n","df['loan_amnt'] = df['loan_amnt'].astype('uint32')\n","df['loan_int_rate'] = df['loan_int_rate'].astype('float32')\n","df['loan_status'] = df['loan_status'].astype('uint8')\n","df['loan_percent_income'] = df['loan_percent_income'].astype('float32')\n","df['cb_person_cred_hist_length'] = df['cb_person_cred_hist_length'].astype('uint8')\n","df['missing_emp_length'] = df['missing_emp_length'].astype('uint8')\n","df['missing_loan_rate'] = df['missing_loan_rate'].astype('uint8')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:12:13.327556Z","iopub.status.busy":"2024-11-18T16:12:13.327101Z","iopub.status.idle":"2024-11-18T16:12:13.360034Z","shell.execute_reply":"2024-11-18T16:12:13.358900Z","shell.execute_reply.started":"2024-11-18T16:12:13.327505Z"},"trusted":true},"outputs":[],"source":["# Results show a saving in memory of > 0.9 MB. \n","# This step is more relevant to large datasets and pipelines.\n","df.info()"]},{"cell_type":"markdown","metadata":{},"source":["# Scaling & One-Hot Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.161824Z","iopub.status.busy":"2024-11-18T16:13:00.161386Z","iopub.status.idle":"2024-11-18T16:13:00.274663Z","shell.execute_reply":"2024-11-18T16:13:00.273619Z","shell.execute_reply.started":"2024-11-18T16:13:00.161778Z"},"trusted":true},"outputs":[],"source":["# We are using min-max scaling for continuous variables as the underlying data is not normally distributed\n","from sklearn.preprocessing import MinMaxScaler\n","\n","min_max_scaler = MinMaxScaler()\n","df[['person_age', 'person_income','loan_amnt']] = min_max_scaler.fit_transform(df[['person_age','person_income','loan_amnt']])\n","df.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.276286Z","iopub.status.busy":"2024-11-18T16:13:00.275923Z","iopub.status.idle":"2024-11-18T16:13:00.396647Z","shell.execute_reply":"2024-11-18T16:13:00.395502Z","shell.execute_reply.started":"2024-11-18T16:13:00.276249Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","\n","encoder = OneHotEncoder(drop='first', sparse_output=False)\n","\n","encoded_data = encoder.fit_transform(df[['person_home_ownership','loan_intent','loan_grade']])\n","\n","encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['person_home_ownership','loan_intent','loan_grade']))\n","df_final = pd.concat([df.drop(['person_home_ownership','loan_intent','loan_grade'], axis=1).reset_index(drop=True) , encoded_df.reset_index(drop=True) ], axis=1)\n","\n","df_final.sample(5)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# df_final = df_final[~df_final[\"person_age\"].isna()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.shape[0] - df_final.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.398646Z","iopub.status.busy":"2024-11-18T16:13:00.398182Z","iopub.status.idle":"2024-11-18T16:13:00.462416Z","shell.execute_reply":"2024-11-18T16:13:00.461360Z","shell.execute_reply.started":"2024-11-18T16:13:00.398593Z"},"trusted":true},"outputs":[],"source":["# Converting Ys and Ns to 1s and 0s\n","df_final['cb_person_default_on_file'] = df_final['cb_person_default_on_file'].replace({'Y': 1, 'N': 0})\n","df_final.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.464048Z","iopub.status.busy":"2024-11-18T16:13:00.463651Z","iopub.status.idle":"2024-11-18T16:13:00.489110Z","shell.execute_reply":"2024-11-18T16:13:00.487717Z","shell.execute_reply.started":"2024-11-18T16:13:00.464006Z"},"trusted":true},"outputs":[],"source":["# Mark NaN values in person_emp_length and loan_int_rate\n","\n","df_final['missing_emp_length'] = df_final['person_emp_length'].isnull().astype(int)\n","df_final['missing_int_rate'] = df_final['loan_int_rate'].isnull().astype(int)\n","\n","# Also mark loans with 0 interest as a missing value\n","df_final.loc[df_final['loan_int_rate'] == 0, 'missing_int_rate'] = 1\n","\n","# Let NaNs equal -1 to indicate missing value\n","df_final.loc[df_final['person_emp_length'].isnull(), 'person_emp_length'] = -1\n","df_final.loc[df_final['loan_int_rate'].isnull(), 'loan_int_rate'] = -1\n","\n","df_final.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.500395Z","iopub.status.busy":"2024-11-18T16:13:00.500008Z","iopub.status.idle":"2024-11-18T16:13:00.519804Z","shell.execute_reply":"2024-11-18T16:13:00.518592Z","shell.execute_reply.started":"2024-11-18T16:13:00.500347Z"},"trusted":true},"outputs":[],"source":["df_final.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.521567Z","iopub.status.busy":"2024-11-18T16:13:00.521204Z","iopub.status.idle":"2024-11-18T16:13:00.571233Z","shell.execute_reply":"2024-11-18T16:13:00.570063Z","shell.execute_reply.started":"2024-11-18T16:13:00.521528Z"},"trusted":true},"outputs":[],"source":["df_final[df_final.isnull().any(axis=1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T16:13:00.573073Z","iopub.status.busy":"2024-11-18T16:13:00.572673Z","iopub.status.idle":"2024-11-18T16:13:03.221801Z","shell.execute_reply":"2024-11-18T16:13:03.220701Z","shell.execute_reply.started":"2024-11-18T16:13:00.573033Z"},"trusted":true},"outputs":[],"source":["# Assuming your DataFrame is df\n","correlation_matrix = df_final.corr()\n","\n","# Plot heatmap\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import statsmodels.api as sm\n","from statsmodels.formula.api import ols\n","\n","# Assuming df has a continuous variable (e.g., 'loan_amount') and a categorical target (e.g., 'loan_status')\n","model = ols('loan_status ~ person_income + loan_int_rate + loan_percent_income', data=df_final).fit()\n","anova_table = sm.stats.anova_lm(model, typ=2)\n","print(anova_table)\n","\n","# 'loan_int_rate', 'loan_percent_income', 'person_home_ownership_RENT', 'person_income'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Prepare the data (features and labels)\n","X = df_final.drop('loan_status', axis=1)  # Features\n","y = df_final['loan_status']  # Target label\n","\n","# Step 2: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Step 3: Define the column transformer for preprocessing\n","# - StandardScaler for numerical columns: 'age', 'income', 'credit_score'\n","# # - OneHotEncoder for categorical columns: 'gender'\n","# preprocessor = ColumnTransformer(\n","#     transformers=[\n","#         ('num', StandardScaler(), ['age', 'income', 'credit_score']),\n","#         ('cat', OneHotEncoder(drop='first'), ['gender'])\n","#     ])\n","\n","# Step 3: Create and train the Logistic Regression model\n","classifier = LogisticRegression(solver='liblinear')  # 'liblinear' is a good choice for smaller datasets\n","classifier.fit(X_train, y_train)\n","\n","# Step 4: Make predictions\n","y_pred = classifier.predict(X_test)\n","\n","# Step 5: Evaluate the model\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n","print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Create and train the Logistic Regression model\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Step 2: Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 3: Evaluate the model's accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy:.2f}\")\n","\n","# Optional: Print detailed evaluation metrics\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Create and train the SVM model\n","model = SVC()  # By default, SVC uses an RBF kernel\n","model.fit(X_train, y_train)\n","\n","# Step 2: Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 3: Evaluate the model's accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy:.2f}\")\n","\n","# Optional: Print detailed evaluation metrics\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Create and train the Decision Tree model\n","model = DecisionTreeClassifier()\n","model.fit(X_train, y_train)\n","\n","# Step 2: Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 3: Evaluate the model's accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy:.2f}\")\n","\n","# Optional: Print detailed evaluation metrics\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Create and train the Random Forest model\n","model = RandomForestClassifier()\n","model.fit(X_train, y_train)\n","\n","# Step 2: Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 3: Evaluate the model's accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy:.2f}\")\n","\n","# Optional: Print detailed evaluation metrics\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# !pip uninstall  numpy"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.model_selection import GridSearchCV\n","# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# # Define the parameter grid\n","# param_grid = {\n","#     'n_estimators': [50, 100, 200],        # Number of trees\n","#     'max_depth': [None, 10, 20, 30],        # Depth of trees\n","#     'min_samples_split': [2, 5, 10],        # Minimum samples to split a node\n","#     'min_samples_leaf': [1, 2, 4],          # Minimum samples per leaf\n","#     'criterion': ['gini', 'entropy']       # Splitting criteria\n","# }\n","\n","# # Create the Random Forest model\n","# rf = RandomForestClassifier(random_state=42)\n","\n","# # Perform Grid Search\n","# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n","#                            cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n","\n","# # Fit the grid search to the training data\n","# grid_search.fit(X_train, y_train)\n","\n","# # Best parameters from Grid Search\n","# print(\"Best Parameters from GridSearchCV:\")\n","# print(grid_search.best_params_)\n","\n","# # Train the model with the best parameters\n","# best_rf_model = grid_search.best_estimator_\n","\n","# # Evaluate the tuned model on the test set\n","# y_pred_best = best_rf_model.predict(X_test)\n","# best_accuracy = accuracy_score(y_test, y_pred_best)\n","# print(f\"Random Forest Accuracy (with best parameters): {best_accuracy:.2f}\")\n","\n","# print(\"\\nClassification Report (Best Model):\")\n","# print(classification_report(y_test, y_pred_best))\n","\n","# print(\"\\nConfusion Matrix (Best Model):\")\n","# print(confusion_matrix(y_test, y_pred_best))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Step 1: Create and train the XGBoost model\n","xgb_model = XGBClassifier()\n","xgb_model.fit(X_train, y_train)\n","\n","# Step 2: Make predictions on the test set\n","xgb_y_pred = xgb_model.predict(X_test)\n","\n","# Step 3: Evaluate the model's accuracy\n","xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n","print(\"XGBoost Model Accuracy:\", xgb_accuracy)\n","print(\"\\nXGBoost Classification Report:\\n\", classification_report(y_test, xgb_y_pred))\n","print(\"\\nXGBoost Confusion Matrix:\\n\", confusion_matrix(y_test, xgb_y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from lightgbm import LGBMClassifier\n","\n","# Step 1: Create and train the LightGBM model\n","lgb_model = LGBMClassifier()\n","lgb_model.fit(X_train, y_train)\n","\n","# Step 2: Make predictions on the test set\n","lgb_y_pred = lgb_model.predict(X_test)\n","\n","# Step 3: Evaluate the model's accuracy\n","lgb_accuracy = accuracy_score(y_test, lgb_y_pred)\n","print(\"LightGBM Model Accuracy:\", lgb_accuracy)\n","print(\"\\nLightGBM Classification Report:\\n\", classification_report(y_test, lgb_y_pred))\n","print(\"\\nLightGBM Confusion Matrix:\\n\", confusion_matrix(y_test, lgb_y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# With Hyperparameter tuning using GridSearchCV\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'max_depth': [3, 5, 7],\n","    'min_child_weight': [1, 3, 5],\n","    'subsample': [0.7, 0.8, 0.9],\n","    'colsample_bytree': [0.7, 0.8, 0.9]\n","}\n","\n","best_params = {\n","    'colsample_bytree': 0.9,\n","    'learning_rate': 0.1,\n","    'max_depth': 5,\n","    'min_child_weight': 1,\n","    'n_estimaors': 300,\n","    'subsample': 0.9\n","}\n","\n","best_model = XGBClassifier(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Grid Search\n","# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=2, n_jobs=1)\n","\n","# grid_search.fit(X_train, y_train)\n","\n","# best_params = grid_search.best_params_\n","# best_model = grid_search.best_estimator_\n","\n","y_pred = best_model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Best Hyperparameters:\", best_params)\n","print(\"Accuracy:\", accuracy)\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"Classification Report:\\n\", class_report)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4675026,"sourceId":7949759,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"loan_approval","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":4}
